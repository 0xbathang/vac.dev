<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>What&#x27;s the Plan for Waku v2?</title><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta name="description" content="Read about our plans for Waku v2, moving to libp2p, better routing, adaptive nodes and accounting!"/><link rel="shortcut icon" href="/assets/logo/vac/favicon.ico"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="vacp2p"/><meta name="twitter:site" content="@vacp2p"/><meta name="twitter:title" content="What&#x27;s the Plan for Waku v2?"/><meta name="twitter:description" content="Read about our plans for Waku v2, moving to libp2p, better routing, adaptive nodes and accounting!"/><meta name="twitter:image" content="https://staging.vac.dev/compiled-assets/img/status_scaling_model_fig4.png"/><meta property="og:url" content="https://staging.vac.dev//waku-v2-plan"/><meta property="og:image" content="https://staging.vac.dev/compiled-assets/img/status_scaling_model_fig4.png"/><meta property="og:site_name" content="What&#x27;s the Plan for Waku v2?"/><meta property="og:title" content="What&#x27;s the Plan for Waku v2?"/><meta property="og:description" content="Read about our plans for Waku v2, moving to libp2p, better routing, adaptive nodes and accounting!"/><meta name="next-head-count" content="16"/><link rel="preload" href="/_next/static/css/e068b41030ceede6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/e068b41030ceede6.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cdd95df0746869ac.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cdd95df0746869ac.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-a14325fd952bf0eb.js" defer=""></script><script src="/_next/static/chunks/framework-fc97f3f1282ce3ed.js" defer=""></script><script src="/_next/static/chunks/main-ada0258e433ba222.js" defer=""></script><script src="/_next/static/chunks/pages/_app-ddaa6fd0b662f230.js" defer=""></script><script src="/_next/static/chunks/eb1842f2-90eb16656390ba2a.js" defer=""></script><script src="/_next/static/chunks/399-b4b9981c243e7c94.js" defer=""></script><script src="/_next/static/chunks/22-60872adba37ba5bb.js" defer=""></script><script src="/_next/static/chunks/pages/%5B%5B...path%5D%5D-e5cc32395b198f36.js" defer=""></script><script src="/_next/static/eRPxRFLrljDMNz1vMxWIY/_buildManifest.js" defer=""></script><script src="/_next/static/eRPxRFLrljDMNz1vMxWIY/_ssgManifest.js" defer=""></script><script src="/_next/static/eRPxRFLrljDMNz1vMxWIY/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><svg width="0" height="0" xmlns="http://www.w3.org/2000/svg" style="display:none"><defs><filter id="colored"><feColorMatrix type="matrix" values="1.00 0 0 0 0 0 1.00 0 0 0 0 0 1.00 0 0 0 0 0 1 0"></feColorMatrix></filter></defs></svg><style nonce="logos">
      #nprogress {
        pointer-events: none;
      }
      #nprogress .bar {
        background: #000000;
        position: fixed;
        z-index: 9999;
        top: 0;
        left: 0;
        width: 100%;
        height: 3px;
      }
      #nprogress .peg {
        display: block;
        position: absolute;
        right: 0px;
        width: 100px;
        height: 100%;
        box-shadow: 0 0 10px #000000, 0 0 5px #000000;
        opacity: 1;
        -webkit-transform: rotate(3deg) translate(0px, -4px);
        -ms-transform: rotate(3deg) translate(0px, -4px);
        transform: rotate(3deg) translate(0px, -4px);
      }
      #nprogress .spinner {
        display: block;
        position: fixed;
        z-index: 1031;
        top: 15px;
        right: 15px;
      }
      #nprogress .spinner-icon {
        width: 18px;
        height: 18px;
        box-sizing: border-box;
        border: solid 2px transparent;
        border-top-color: #000000;
        border-left-color: #000000;
        border-radius: 50%;
        -webkit-animation: nprogresss-spinner 400ms linear infinite;
        animation: nprogress-spinner 400ms linear infinite;
      }
      .nprogress-custom-parent {
        overflow: hidden;
        position: relative;
      }
      .nprogress-custom-parent #nprogress .spinner,
      .nprogress-custom-parent #nprogress .bar {
        position: absolute;
      }
      @-webkit-keyframes nprogress-spinner {
        0% {
          -webkit-transform: rotate(0deg);
        }
        100% {
          -webkit-transform: rotate(360deg);
        }
      }
      @keyframes nprogress-spinner {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }
    </style><div class="Style_container__qv2Yk Styles_common_container__u_XHj template-container"><header class="Styles_container__5FUI_ Style_header__IYvBP undefined"><div class="Styles_innerWrapper__ZInvp"><div class="logo-holder button vac" style="display:inline-block"><svg width="45" height="43" viewBox="0 0 35 43" fill="none" xmlns="http://www.w3.org/2000/svg" class="vac-logo"><g clip-path="url(#clip0_917_3082)"><path d="M24.9034 14.8217C24.6824 11.2666 23.5308 7.8298 21.5623 4.84994C22.543 4.19721 23.7374 3.93844 24.9034 4.12603C25.492 4.23064 26.0472 4.4722 26.5233 4.83086C26.9994 5.18951 27.3828 5.65504 27.6421 6.18916C28.0141 7.1512 28.1335 8.19117 27.989 9.21147C27.9754 9.6728 27.8955 10.1299 27.7516 10.5688C27.6613 10.8504 27.5322 11.1183 27.3682 11.3651C27.166 11.69 26.9466 12.0041 26.7109 12.3062C26.1084 13.1206 25.5607 14.0073 24.9034 14.8217Z" fill="#999999"></path><path d="M16.7058 7.58268C15.8382 5.99003 14.5344 4.67263 12.9447 3.78217L10.9546 2.69631C10.9546 2.69631 13.2551 -0.778436 16.1945 0.162641C19.134 1.10372 18.1846 7.4017 17.5821 9.80869" fill="#4D4D4D"></path><path d="M20.3209 41.6243C17.4179 40.4118 16.2129 38.3668 14.6975 36.919C13.1821 35.4711 12.8717 29.3903 13.1638 24.6126C13.456 19.8348 17.4909 11.528 17.5822 9.80869C17.6735 8.08941 15.4643 5.17569 13.5655 3.78217C11.6491 2.2631 9.29769 1.38272 6.84668 1.2666L8.36207 2.51534C9.74965 3.67359 9.42101 3.98125 9.22018 6.26155C9.01935 8.54185 8.72722 15.6904 8.70896 21.8436C8.70896 30.3495 6.73713 32.7022 13.0178 38.8373C14.1564 40.1358 15.6863 41.0368 17.3814 41.4072C21.6902 43.036 24.228 43.2712 20.3209 41.6243Z" fill="#1A1A1A"></path><path d="M17.9839 7.07618C17.5904 9.58823 16.8212 12.0281 15.7016 14.3152C14.6765 16.6746 13.7925 19.0918 13.0543 21.5543C12.076 25.3846 11.8405 29.3642 12.3605 33.2816C12.4325 34.6426 12.8065 35.9712 13.4559 37.1726C14.1362 38.1272 14.9759 38.9596 15.939 39.6338C17.8321 41.3312 20.1651 42.4718 22.6761 42.9276C20.068 40.8547 18.189 38.0165 17.3083 34.8199C16.3002 31.5246 16.6412 27.9684 18.2577 24.9205C18.7142 24.0699 19.2436 23.2555 19.7731 22.4411L24.4653 15.3287C24.7022 15.0187 24.8815 14.6694 24.9948 14.2971C25.0769 13.891 25.0769 13.4727 24.9948 13.0665C24.3347 9.48034 22.792 6.11109 20.5034 3.25758C19.9266 2.35717 19.1529 1.59688 18.2395 1.033C17.3262 0.46911 16.2966 0.116066 15.2269 0C15.7121 0.03052 16.1783 0.198543 16.5699 0.484084C16.9616 0.769625 17.2622 1.16066 17.4361 1.61069C17.8159 2.51034 18.0085 3.47679 18.0021 4.45202C18.0507 5.32627 18.0446 6.20267 17.9839 7.07618Z" fill="#808080"></path><path d="M34.927 21.7174C34.8742 21.5895 34.8068 21.4681 34.7261 21.3554C34.5725 21.0145 34.3893 20.6875 34.1784 20.3781C34.0141 20.1429 33.8315 19.9257 33.6489 19.7085C33.2107 19.1294 33.0829 18.3874 32.5352 17.8988C32.2726 17.6504 32.0907 17.33 32.0126 16.9787C31.9346 16.6273 31.964 16.2609 32.097 15.9261C32.2066 15.6366 32.4074 15.4013 32.5352 15.1298C32.6706 14.7258 32.7195 14.2982 32.6786 13.8744C32.6378 13.4505 32.5081 13.0398 32.2979 12.6685C31.7956 11.6016 31.1838 10.5888 30.4721 9.64624C29.5227 8.32511 28.5185 7.05828 27.4596 5.82764C27.6672 6.89431 27.6423 7.99266 27.3865 9.04902C27.2386 9.62495 27.0432 10.1879 26.8023 10.7321C26.4264 11.4007 26.0118 12.0473 25.5608 12.6685C23.2238 16.2881 20.832 19.9076 18.349 23.4004C17.0435 25.5573 16.3321 28.0161 16.2859 30.5309C16.0848 32.9993 16.618 35.472 17.8195 37.6433C18.5687 38.8742 19.4502 40.021 20.4486 41.0637C21.0694 41.7334 21.7814 42.8735 22.6395 43.0726C22.7491 42.041 22.9499 40.6475 23.096 39.6159C23.3338 37.934 23.8782 36.3089 24.7027 34.8201C25.1895 33.7601 26.0543 32.9158 27.1309 32.4493C27.9135 32.2862 28.7218 32.2862 29.5044 32.4493C29.9422 32.4221 30.3812 32.4221 30.819 32.4493C31.2686 32.4735 31.7149 32.3597 32.097 32.1235C32.3186 31.968 32.5024 31.7655 32.6351 31.5307C32.7677 31.2959 32.8459 31.0347 32.8638 30.7662C32.9186 30.2791 32.9186 29.7874 32.8638 29.3003C32.8245 28.9868 32.8685 28.6686 32.9916 28.3773C33.2473 27.8525 34.0141 27.6172 34.0689 27.02C34.0476 26.7523 33.9665 26.4927 33.8315 26.2599C33.7604 26.1456 33.7228 26.014 33.7228 25.8798C33.7228 25.7456 33.7604 25.614 33.8315 25.4998C33.8315 25.4998 34.0506 25.355 34.1236 25.2464C34.2051 25.1396 34.2492 25.0093 34.2492 24.8754C34.2492 24.7415 34.2051 24.6112 34.1236 24.5044C33.9428 24.2955 33.8006 24.0566 33.7037 23.7986C33.695 23.6656 33.715 23.5323 33.7622 23.4075C33.8094 23.2827 33.8828 23.1692 33.9776 23.0747C34.1732 22.888 34.3945 22.7295 34.6348 22.6041C34.7511 22.5516 34.8541 22.4739 34.9362 22.3769C35.0183 22.2798 35.0776 22.1658 35.1095 22.0431C35.0688 21.9246 35.0069 21.8143 34.927 21.7174Z" fill="#CCCCCC"></path><path d="M34.3062 20.5771C34.478 20.8248 34.619 21.0922 34.7261 21.3734C34.8037 21.4816 34.8709 21.5967 34.9269 21.7173L34.3062 20.5771Z" fill="#CCCCCC"></path><path d="M10.133 33.4262C9.0523 28.5693 8.7138 23.5789 9.12886 18.6223C9.12886 16.1429 11.265 2.44302 7.79605 1.41145C4.85656 0.524668 2.53783 3.94512 2.53783 3.94512C0.667683 7.68216 -0.206002 11.8316 1.36513e-05 15.9982C2.30048 38.8193 17.6735 41.4615 18.2577 41.7149C18.2577 41.7149 11.4476 39.2898 10.133 33.4262Z" fill="#09212A"></path></g><defs><clipPath id="clip0_917_3082"><rect width="35" height="43"></rect></clipPath></defs></svg></div><div class="Styles_searchBox__5X2m1"><div class="Styles_container__ddCFx "><div class="logos-search-box Styles_searchBox__xWHyX"><div><input type="text" placeholder="Search Vac Research" value=""/></div></div></div></div></div></header><div class="page-info"><h1 style="display:none">Vac Research</h1><div class="page-info-sub"><i>Apr 28 2023</i><br/><span>staging.vac.dev</span></div></div><main class="undefined Styles_common_main__4v7gP Styles_common_main__4v7gP"><aside class="Styles_container__3yUcn Style_sidebar__mLS5A Styles_common_sidebar__QAVov hidden-scroll Styles_hideDesktopToggleButton__L_Rik"><div class="sidebar-toggle-button button Styles_mobile___qAwf"><svg width="16" height="16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M1 4h14c.55 0 1-.45 1-1s-.45-1-1-1H1c-.55 0-1 .45-1 1s.45 1 1 1Zm14 8H1c-.55 0-1 .45-1 1s.45 1 1 1h14c.55 0 1-.45 1-1s-.45-1-1-1Zm0-5H1c-.55 0-1 .45-1 1s.45 1 1 1h14c.55 0 1-.45 1-1s-.45-1-1-1Z" fill="#F2F2F2"></path></svg></div><div class="logo-holder button vac" style="display:inline-block"><svg width="45" height="43" viewBox="0 0 35 43" fill="none" xmlns="http://www.w3.org/2000/svg" class="vac-logo"><g clip-path="url(#clip0_917_3082)"><path d="M24.9034 14.8217C24.6824 11.2666 23.5308 7.8298 21.5623 4.84994C22.543 4.19721 23.7374 3.93844 24.9034 4.12603C25.492 4.23064 26.0472 4.4722 26.5233 4.83086C26.9994 5.18951 27.3828 5.65504 27.6421 6.18916C28.0141 7.1512 28.1335 8.19117 27.989 9.21147C27.9754 9.6728 27.8955 10.1299 27.7516 10.5688C27.6613 10.8504 27.5322 11.1183 27.3682 11.3651C27.166 11.69 26.9466 12.0041 26.7109 12.3062C26.1084 13.1206 25.5607 14.0073 24.9034 14.8217Z" fill="#999999"></path><path d="M16.7058 7.58268C15.8382 5.99003 14.5344 4.67263 12.9447 3.78217L10.9546 2.69631C10.9546 2.69631 13.2551 -0.778436 16.1945 0.162641C19.134 1.10372 18.1846 7.4017 17.5821 9.80869" fill="#4D4D4D"></path><path d="M20.3209 41.6243C17.4179 40.4118 16.2129 38.3668 14.6975 36.919C13.1821 35.4711 12.8717 29.3903 13.1638 24.6126C13.456 19.8348 17.4909 11.528 17.5822 9.80869C17.6735 8.08941 15.4643 5.17569 13.5655 3.78217C11.6491 2.2631 9.29769 1.38272 6.84668 1.2666L8.36207 2.51534C9.74965 3.67359 9.42101 3.98125 9.22018 6.26155C9.01935 8.54185 8.72722 15.6904 8.70896 21.8436C8.70896 30.3495 6.73713 32.7022 13.0178 38.8373C14.1564 40.1358 15.6863 41.0368 17.3814 41.4072C21.6902 43.036 24.228 43.2712 20.3209 41.6243Z" fill="#1A1A1A"></path><path d="M17.9839 7.07618C17.5904 9.58823 16.8212 12.0281 15.7016 14.3152C14.6765 16.6746 13.7925 19.0918 13.0543 21.5543C12.076 25.3846 11.8405 29.3642 12.3605 33.2816C12.4325 34.6426 12.8065 35.9712 13.4559 37.1726C14.1362 38.1272 14.9759 38.9596 15.939 39.6338C17.8321 41.3312 20.1651 42.4718 22.6761 42.9276C20.068 40.8547 18.189 38.0165 17.3083 34.8199C16.3002 31.5246 16.6412 27.9684 18.2577 24.9205C18.7142 24.0699 19.2436 23.2555 19.7731 22.4411L24.4653 15.3287C24.7022 15.0187 24.8815 14.6694 24.9948 14.2971C25.0769 13.891 25.0769 13.4727 24.9948 13.0665C24.3347 9.48034 22.792 6.11109 20.5034 3.25758C19.9266 2.35717 19.1529 1.59688 18.2395 1.033C17.3262 0.46911 16.2966 0.116066 15.2269 0C15.7121 0.03052 16.1783 0.198543 16.5699 0.484084C16.9616 0.769625 17.2622 1.16066 17.4361 1.61069C17.8159 2.51034 18.0085 3.47679 18.0021 4.45202C18.0507 5.32627 18.0446 6.20267 17.9839 7.07618Z" fill="#808080"></path><path d="M34.927 21.7174C34.8742 21.5895 34.8068 21.4681 34.7261 21.3554C34.5725 21.0145 34.3893 20.6875 34.1784 20.3781C34.0141 20.1429 33.8315 19.9257 33.6489 19.7085C33.2107 19.1294 33.0829 18.3874 32.5352 17.8988C32.2726 17.6504 32.0907 17.33 32.0126 16.9787C31.9346 16.6273 31.964 16.2609 32.097 15.9261C32.2066 15.6366 32.4074 15.4013 32.5352 15.1298C32.6706 14.7258 32.7195 14.2982 32.6786 13.8744C32.6378 13.4505 32.5081 13.0398 32.2979 12.6685C31.7956 11.6016 31.1838 10.5888 30.4721 9.64624C29.5227 8.32511 28.5185 7.05828 27.4596 5.82764C27.6672 6.89431 27.6423 7.99266 27.3865 9.04902C27.2386 9.62495 27.0432 10.1879 26.8023 10.7321C26.4264 11.4007 26.0118 12.0473 25.5608 12.6685C23.2238 16.2881 20.832 19.9076 18.349 23.4004C17.0435 25.5573 16.3321 28.0161 16.2859 30.5309C16.0848 32.9993 16.618 35.472 17.8195 37.6433C18.5687 38.8742 19.4502 40.021 20.4486 41.0637C21.0694 41.7334 21.7814 42.8735 22.6395 43.0726C22.7491 42.041 22.9499 40.6475 23.096 39.6159C23.3338 37.934 23.8782 36.3089 24.7027 34.8201C25.1895 33.7601 26.0543 32.9158 27.1309 32.4493C27.9135 32.2862 28.7218 32.2862 29.5044 32.4493C29.9422 32.4221 30.3812 32.4221 30.819 32.4493C31.2686 32.4735 31.7149 32.3597 32.097 32.1235C32.3186 31.968 32.5024 31.7655 32.6351 31.5307C32.7677 31.2959 32.8459 31.0347 32.8638 30.7662C32.9186 30.2791 32.9186 29.7874 32.8638 29.3003C32.8245 28.9868 32.8685 28.6686 32.9916 28.3773C33.2473 27.8525 34.0141 27.6172 34.0689 27.02C34.0476 26.7523 33.9665 26.4927 33.8315 26.2599C33.7604 26.1456 33.7228 26.014 33.7228 25.8798C33.7228 25.7456 33.7604 25.614 33.8315 25.4998C33.8315 25.4998 34.0506 25.355 34.1236 25.2464C34.2051 25.1396 34.2492 25.0093 34.2492 24.8754C34.2492 24.7415 34.2051 24.6112 34.1236 24.5044C33.9428 24.2955 33.8006 24.0566 33.7037 23.7986C33.695 23.6656 33.715 23.5323 33.7622 23.4075C33.8094 23.2827 33.8828 23.1692 33.9776 23.0747C34.1732 22.888 34.3945 22.7295 34.6348 22.6041C34.7511 22.5516 34.8541 22.4739 34.9362 22.3769C35.0183 22.2798 35.0776 22.1658 35.1095 22.0431C35.0688 21.9246 35.0069 21.8143 34.927 21.7174Z" fill="#CCCCCC"></path><path d="M34.3062 20.5771C34.478 20.8248 34.619 21.0922 34.7261 21.3734C34.8037 21.4816 34.8709 21.5967 34.9269 21.7173L34.3062 20.5771Z" fill="#CCCCCC"></path><path d="M10.133 33.4262C9.0523 28.5693 8.7138 23.5789 9.12886 18.6223C9.12886 16.1429 11.265 2.44302 7.79605 1.41145C4.85656 0.524668 2.53783 3.94512 2.53783 3.94512C0.667683 7.68216 -0.206002 11.8316 1.36513e-05 15.9982C2.30048 38.8193 17.6735 41.4615 18.2577 41.7149C18.2577 41.7149 11.4476 39.2898 10.133 33.4262Z" fill="#09212A"></path></g><defs><clipPath id="clip0_917_3082"><rect width="35" height="43"></rect></clipPath></defs></svg></div><div class="Styles_desktop__VH2y3 defaultSidebar Styles_container__4YC7p"><nav class="sidebarNav hidden-scroll"><ul class="sidebar-menu mainMenu Styles_menu__izFC1"><li class="Styles_menuItem__BqRqE menuitem level-0"><span></span><ul class="sidebar-menu  Styles_menu__izFC1"><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Main" href="/">Main</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="principles" href="/principles">Principles</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Research areas" href="/research-areas">Research areas</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Projects" href="/projects">Projects</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Open Research Problems" href="/open-problems">Open Research Problems</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="publications" href="/publications">Publications</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="contribute" href="/contribute">Contribute</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="media" href="/media">Media</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li></ul><br/></li></ul><br/><ul class="sidebar-menu subMenu Styles_menu__izFC1"><li class="Styles_menuItem__BqRqE menuitem level-0"><a class="" title="research" href="/research">Research</a><ul class="sidebar-menu  Styles_menu__izFC1"><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Device Pairing in Js-waku and Go-waku" href="/device-pairing-in-js-waku-and-go-waku">Device Pairing in Js-waku and Go-waku</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="The Future of Waku Network: Scaling, Incentivization, and Heterogeneity" href="/future-of-waku-network">The Future of Waku Network: Scaling, Incentivization, and Heterogeneity</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Waku for All Decentralized Applications and Infrastructures" href="/waku-for-all">Waku for All Decentralized Applications and Infrastructures</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Building Privacy-Protecting Infrastructure" href="/building-privacy-protecting-infrastructure">Building Privacy-Protecting Infrastructure</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Waku Privacy and Anonymity Analysis Part I: Definitions and Waku Relay" href="/wakuv2-relay-anon">Waku Privacy and Anonymity Analysis Part I: Definitions and Waku Relay</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Noise handshakes as key-exchange mechanism for Waku" href="/wakuv2-noise">Noise handshakes as key-exchange mechanism for Waku</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li class="Styles_menuItem__BqRqE menuitem level-1"><a class="" title="Waku v2 Ambient Peer Discovery" href="/wakuv2-apd">Waku v2 Ambient Peer Discovery</a><ul class="sidebar-menu  Styles_menu__izFC1"></ul></li><li><span class="button">...</span></li></ul><br/></li></ul><div class="external_links"><div><div class="menuitem-title"><span class="cap">Resources</span></div><ul><li><a href="https://rfc.vac.dev/" target="_blank">&gt; Specs/RFCs</a></li><li><a href="https://forum.vac.dev/" target="_blank">&gt; Forum</a></li><li><a href="https://waku.org" target="_blank">&gt; Waku.org</a></li></ul></div></div></nav></div></aside><article class="Styles_container__pG0bG Style_content__NTXHZ Styles_common_content__Myi5Z"><div class="Style_container__qc2tD"><h2 class="Style_container__eSI4Q serif">What&#x27;s the Plan for Waku v2?</h2><div class="serif"><i>Jul 01 2020</i><i> - </i>by<!-- --><a title="oskarth" href="/authors/oskarth"><span><i> <!-- -->oskarth<!-- --></i></span></a></div></div><p><strong>tldr: The Waku network is fragile and doesn&#x27;t scale. Here&#x27;s how to solve it.<!-- --></strong></p>
<!-- --><p><em>NOTE: This post was originally written with Status as a primary use case in mind, which reflects how we talk about some problems here. However, Waku v2 is a general-purpose private p2p messaging protocol, especially for people running in resource restricted environments.<!-- --></em></p>
<!-- --><h1><a class="anchor" id="problem"></a><a class="ha" href="#problem">Problem<!-- --></a></h1>
<!-- --><p>The Waku network is fragile and doesn&#x27;t scale.<!-- --></p>
<!-- --><p>As <!-- --><a href="https://status.im">Status<!-- --></a> is moving into a user-acquisition phase and is improving retention rates for users they need the infrastructure to keep up, specifically when it comes to messaging.<!-- --></p>
<!-- --><p>Based on user acquisition models, the initial goal is to support 100k DAU in September, with demand growing from there.<!-- --></p>
<!-- --><p>With the Status Scaling Model we have studied the current bottlenecks as a function of concurrent users (CCU) and daily active users (DAU). Here are the conclusions.<!-- --></p>
<!-- --><p><strong><strong>1. Connection limits<!-- --></strong></strong>. With 100 full nodes we reach ~10k CCU based on connection limits. This can primarily be addressed by increasing the number of nodes (cluster or user operated). This assumes node discovery works. It is also worth investigating the limitations of max number of connections, though this is likely to be less relevant for user-operated nodes. For a user-operated network, this means 1% of users have to run a full node. See Fig 1-2.<!-- --></p>
<!-- --><p><strong><strong>2. Bandwidth as a bottleneck<!-- --></strong></strong>. We notice that memory usage appears to not be
the primary bottleneck for full nodes, and the bottleneck is still bandwidth. To support 10k DAU, and full nodes with an amplification factor of 25 the required Internet speed is ~50 Mbps, which is a fast home Internet connection. For ~100k DAU only cloud-operated nodes can keep up (500 Mbps). See Fig 3-5.<!-- --></p>
<!-- --><p><strong><strong>3. Amplification factors<!-- --></strong></strong>. Reducing amplification factors with better routing, would have a high impact, but it is likely we&#x27;d need additional measures as well, such as topic sharding or similar. See Fig 8-13.<!-- --></p>
<!-- --><p>Figure 1-5:<!-- --></p>
<!-- --><div class="rehype-figure-container"><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig1.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig2.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig3.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig4.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig5.png" alt=""/></figure></div>
<!-- --><p>See <!-- --><a href="https://colab.research.google.com/drive/1Fz-oxRxxAFPpM1Cowpnb0nT52V1-yeRu#scrollTo=Yc3417FUJJ_0">https://colab.research.google.com/drive/1Fz-oxRxxAFPpM1Cowpnb0nT52V1-yeRu#scrollTo=Yc3417FUJJ_0<!-- --></a> for the full report.<!-- --></p>
<!-- --><p>What we need to do is:<!-- --></p>
<!-- --><ol>
<!-- --><li>Reduce amplification factors<!-- --></li>
<!-- --><li>Get more user-run full nodes<!-- --></li>
<!-- --></ol>
<!-- --><p>Doing this means the Waku network will be able to scale, and doing so in the right way, in a robust fashion. What would a fragile way of scaling be? Increasing our reliance on a Status Pte Ltd operated cluster which would paint us in a corner where we:<!-- --></p>
<!-- --><ul>
<!-- --><li>keep increasing requirements for Internet speed for full nodes<!-- --></li>
<!-- --><li>are vulnerable to censorship and attacks<!-- --></li>
<!-- --><li>have to control the topology in an artifical manner to keep up with load<!-- --></li>
<!-- --><li>basically re-invent a traditional centralized client-server app with extra steps<!-- --></li>
<!-- --><li>deliberately ignore most of our principles<!-- --></li>
<!-- --><li>risk the network being shut down when we run out of cash<!-- --></li>
<!-- --></ul>
<!-- --><h1><a class="anchor" id="appetite"></a><a class="ha" href="#appetite">Appetite<!-- --></a></h1>
<!-- --><p>Our initial risk appetite for this is 6 weeks for a small team.<!-- --></p>
<!-- --><p>The idea is that we want to make tangible progress towards the goal in a limited period of time, as opposed to getting bogged down in trying to find a theoretically perfect generalized solution. Fixed time, variable scope.<!-- --></p>
<!-- --><p>It is likely some elements of a complete solution will be done separately. See later sections for that.<!-- --></p>
<!-- --><h1><a class="anchor" id="solution"></a><a class="ha" href="#solution">Solution<!-- --></a></h1>
<!-- --><p>There are two main parts of the solution. One is to reduce amplification factors, and the other is incentivization to get more user run full nodes with desktop, etc.<!-- --></p>
<!-- --><p>What does a full node provide? It provides connectivity to the network, can act as a bandwidth &quot;barrier&quot; and be high or reasonably high availability. What this means right now is essentially topic interest and storing historical messages.<!-- --></p>
<!-- --><p>The goal is here to improve the status quo, not get a perfect solution from the get go. All of this can be iterated on further, for stronger guarantees, as well as replaced by other new modules.<!-- --></p>
<!-- --><p>Let&#x27;s first look at the baseline, and then go into some of the tracks and their phases. Track 1 is best done first, after which track 2 and 3 can be executed in parallel. Track 1 gives us more options for track 2 and 3. The work in track 1 is currently more well-defined, so it is likely the specifics of track 2 and 3 will get refined at a later stage.<!-- --></p>
<!-- --><h2><a class="anchor" id="baseline"></a><a class="ha" href="#baseline">Baseline<!-- --></a></h2>
<!-- --><p>Here&#x27;s where we are at now. In reality, the amplification factor are likely even worse than this (15 in the graph below), up to 20-30. Especially with an open network, where we can&#x27;t easily control connectivity and availability of nodes. Left unchecked, with a full mesh, it could even go as high x100, though this is likely excessive and can be dialed down. See scaling model for more details.<!-- --></p>
<!-- --><figure class="rehype-figure"><img src="/compiled-assets/img/waku_v1_routing_small.png" alt=""/></figure>
<!-- --><h2><a class="anchor" id="track-1---move-to-libp2p"></a><a class="ha" href="#track-1---move-to-libp2p">Track 1 - Move to libp2p<!-- --></a></h2>
<!-- --><p>Moving to PubSub over libp2p wouldn&#x27;t improve amplification per se, but it would be stepping stone. Why? It paves the way for GossipSub, and would be a checkpoint on this journey. Additionally, FloodSub and GossipSub are compatible, and very likely other future forms of PubSub such as GossipSub 1.1 (hardened/more secure), EpiSub, forwarding Kademlia / PubSub over Kademlia, etc. Not to mention security This would also give us access to the larger libp2p ecosystem (multiple protocols, better encryption, quic, running in the browser, security audits, etc, etc), as well as be a joint piece of infrastructured used for Eth2 in Nimbus. More wood behind fewer arrows.<!-- --></p>
<!-- --><p>See more on libp2p PubSub here: <!-- --><a href="https://docs.libp2p.io/concepts/publish-subscribe/">https://docs.libp2p.io/concepts/publish-subscribe/<!-- --></a></p>
<!-- --><p>As part of this move, there are a few individual pieces that are needed.<!-- --></p>
<!-- --><h3><a class="anchor" id="1-floodsub"></a><a class="ha" href="#1-floodsub">1. FloodSub<!-- --></a></h3>
<!-- --><p>This is essentially what Waku over libp2p would look like in its most basic form.<!-- --></p>
<!-- --><p>One difference that is worth noting is that the app topics would <!-- --><strong>not<!-- --></strong> be the same as Waku topics. Why? In Waku we currently don&#x27;t use topics for routing between full nodes, but only for edge/light nodes in the form of topic interest. In FloodSub, these topics are used for routing.<!-- --></p>
<!-- --><p>Why can&#x27;t we use Waku topics for routing directly? PubSub over libp2p isn&#x27;t built for rare and ephemeral topics, and nodes have to explicitly subscribe to a topic. See topic sharding section for more on this.<!-- --></p>
<!-- --><figure class="rehype-figure"><img src="/compiled-assets/img/waku_v2_routing_flood_small.png" alt=""/></figure>
<!-- --><p>Moving to FloodSub over libp2p would also be an opportunity to clean up and simplify some components that are no longer needed in the Waku v1 protocol, see point below.<!-- --></p>
<!-- --><p>Very experimental and incomplete libp2p support can be found in the nim-waku repo under v2: <!-- --><a href="https://github.com/status-im/nim-waku">https://github.com/status-im/nim-waku<!-- --></a></p>
<!-- --><h3><a class="anchor" id="2-simplify-the-protocol"></a><a class="ha" href="#2-simplify-the-protocol">2. Simplify the protocol<!-- --></a></h3>
<!-- --><p>Due to Waku&#x27;s origins in Whisper, devp2p and as a standalone protocol, there are a lot of stuff that has accumulated (<!-- --><a href="https://rfc.vac.dev/spec/6/">https://rfc.vac.dev/spec/6/<!-- --></a>). Not all of it serves it purpose anymore. For example, do we still need RLP here when we have Protobuf messages? What about extremely low PoW when we have peer scoring? What about key management / encryption when have encryption at libp2p and Status protocol level?<!-- --></p>
<!-- --><p>Not everything has to be done in one go, but being minimalist at this stage will the protocol lean and make us more adaptable.<!-- --></p>
<!-- --><p>The essential characteristic that has to be maintained is that we don&#x27;t need to change the upper layers, i.e. we still deal with (Waku) topics and some envelope like data unit.<!-- --></p>
<!-- --><h3><a class="anchor" id="3-core-integration"></a><a class="ha" href="#3-core-integration">3. Core integration<!-- --></a></h3>
<!-- --><p>As early as possible we want to integrate with Core via Stimbus in order to mitigate risk and catch integration issues early in the process. What this looks like in practice is some set of APIs, similar to how Whisper and Waku were working in parallel, and experimental feature behind a toggle in core/desktop.<!-- --></p>
<!-- --><h3><a class="anchor" id="4-topic-interest-behavior"></a><a class="ha" href="#4-topic-interest-behavior">4. Topic interest behavior<!-- --></a></h3>
<!-- --><p>While we target full node traffic here, we want to make sure we maintain the existing bandwidth requirements for light nodes that Waku v1 addressed (<!-- --><a href="https://vac.dev/fixing-whisper-with-waku">https://vac.dev/fixing-whisper-with-waku<!-- --></a>). This means implementing topic-interest in the form of Waku topics. Note that this would be separate from app topics notes above.<!-- --></p>
<!-- --><h3><a class="anchor" id="5-historical-message-caching"></a><a class="ha" href="#5-historical-message-caching">5. Historical message caching<!-- --></a></h3>
<!-- --><p>Basically what mailservers are currently doing. This likely looks slightly different in a libp2p world. This is another opportunity to simplify things with a basic REQ-RESP architecture, as opposed to the roundabout way things are now. Again, not everything has to be done in one go but there&#x27;s no reason to reimplement a poor API if we don&#x27;t have to.<!-- --></p>
<!-- --><p>Also see section below on adaptive nodes and capabilities.<!-- --></p>
<!-- --><h3><a class="anchor" id="6-waku-v1--libp2p-bridge"></a><a class="ha" href="#6-waku-v1--libp2p-bridge">6. Waku v1 &lt;&gt; Libp2p bridge<!-- --></a></h3>
<!-- --><p>To make the transition complete, there has to a be bridge mode between current Waku and libp2p. This is similar to what was done for Whisper and Waku, and allows any nodes in the network to upgrade to Waku v2 at their leisure. For example, this would likely look different for Core, Desktop, Research and developers.<!-- --></p>
<!-- --><h2><a class="anchor" id="track-2---better-routing"></a><a class="ha" href="#track-2---better-routing">Track 2 - Better routing<!-- --></a></h2>
<!-- --><p>This is where we improve the amplification factors.<!-- --></p>
<!-- --><h3><a class="anchor" id="1-gossipsub"></a><a class="ha" href="#1-gossipsub">1. GossipSub<!-- --></a></h3>
<!-- --><p>This is a subprotocol of FloodSub in the libp2p world. Moving to GossipSub would allow traffic between full nodes to go from an amplification factor of ~25 to ~6. This basically creates a mesh of stable bidirectional connections, together with some gossiping capabilities outside of this view.<!-- --></p>
<!-- --><p>Explaining how GossipSub works is out of scope of this document. It is implemented in nim-libp2p and used by Nimbus as part of Eth2. You can read the specs here in more detail if you are interested: <!-- --><a href="https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.0.md">https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.0.md<!-- --></a> and <!-- --><a href="https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md">https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md<!-- --></a></p>
<!-- --><figure class="rehype-figure"><img src="/compiled-assets/img/waku_v2_routing_gossip_small.png" alt=""/></figure>
<!-- --><div class="rehype-figure-container"><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig8.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig9.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig10.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig11.png" alt=""/></figure></div>
<!-- --><p>While we technically could implement this over existing Waku, we&#x27;d have to re-implement it, and we&#x27;d lose out on all the other benefits libp2p would provide, as well as the ecosystem of people and projects working on improving the scalability and security of these protocols.<!-- --></p>
<!-- --><h3><a class="anchor" id="2-topic-sharding"></a><a class="ha" href="#2-topic-sharding">2. Topic sharding<!-- --></a></h3>
<!-- --><p>This one is slightly more speculative in terms of its ultimate impact. The basic idea is to split the application topic into N shards, say 10, and then each full node can choose which shards to listen to. This can reduce amplification factors by another factor of 10.<!-- --></p>
<!-- --><figure class="rehype-figure"><img src="/compiled-assets/img/waku_v2_routing_sharding_small.png" alt=""/></figure>
<!-- --><div class="rehype-figure-container"><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig12.png" alt=""/></figure><figure class="rehype-figure"><img src="/compiled-assets/img/status_scaling_model_fig13.png" alt=""/></figure></div>
<!-- --><p>Note that this means a light node that listens to several topics would have to be connected to more full nodes to get connectivity. For a more exotic version of this, see <!-- --><a href="https://forum.vac.dev/t/rfc-topic-propagation-extension-to-libp2p-pubsub/47">https://forum.vac.dev/t/rfc-topic-propagation-extension-to-libp2p-pubsub/47<!-- --></a></p>
<!-- --><p>This is orthogonal from the choice of FloodSub or GossipSub, but due to GossipSub&#x27;s more dynamic nature it is likely best combined with it.<!-- --></p>
<!-- --><h3><a class="anchor" id="3-other-factors"></a><a class="ha" href="#3-other-factors">3. Other factors<!-- --></a></h3>
<!-- --><p>Not a primary focus, but worth a look. Looking at the scaling model, there might be other easy wins to improve overall bandwidth consumption between full nodes. For example, can we reduce envelope size by a significant factor?<!-- --></p>
<!-- --><h2><a class="anchor" id="track-3---accounting-and-user-run-nodes"></a><a class="ha" href="#track-3---accounting-and-user-run-nodes">Track 3 - Accounting and user-run nodes<!-- --></a></h2>
<!-- --><p>This is where we make sure the network isn&#x27;t fragile, become a true p2p app, get our users excited and engaged, and allow us to scale the network without creating an even bigger cluster.<!-- --></p>
<!-- --><p>To work in practice, this has a soft dependency on node discovery such as DNS based discovery (<!-- --><a href="https://eips.ethereum.org/EIPS/eip-1459">https://eips.ethereum.org/EIPS/eip-1459<!-- --></a>) or Discovery v5 (<!-- --><a href="https://vac.dev/feasibility-discv5">https://vac.dev/feasibility-discv5<!-- --></a>).<!-- --></p>
<!-- --><h3><a class="anchor" id="1-adaptive-nodes-and-capabilities"></a><a class="ha" href="#1-adaptive-nodes-and-capabilities">1. Adaptive nodes and capabilities<!-- --></a></h3>
<!-- --><p>We want to make the gradation between light nodes, full nodes, storing (partial set of) historical messages, only acting for a specific shard, etc more flexible and explicit. This is required to identify and discover the nodes you want. See <!-- --><a href="https://github.com/vacp2p/specs/issues/87">https://github.com/vacp2p/specs/issues/87<!-- --></a></p>
<!-- --><p>Depending on how the other tracks come together, this design should allow for a desktop node to identify as a full relaying node for some some app topic shard, but also express waku topic interest and retrieve historical messages itself.<!-- --></p>
<!-- --><p>E.g. Disc v5 can be used to supply node properties through ENR.<!-- --></p>
<!-- --><h3><a class="anchor" id="2-accounting"></a><a class="ha" href="#2-accounting">2. Accounting<!-- --></a></h3>
<!-- --><p>This is based on a few principles:<!-- --></p>
<!-- --><ol>
<!-- --><li>Some nodes contribute a lot more than other nodes in the network<!-- --></li>
<!-- --><li>We can account for the difference in contribution in some fashion<!-- --></li>
<!-- --><li>We want to incentivize nodes to tell the true, and be incentivized not to lie<!-- --></li>
<!-- --></ol>
<!-- --><p>Accounting here is a stepping stone, where accounting is the raw data upon which some settlement later occurs. It can have various forms of granularity. See <!-- --><a href="https://forum.vac.dev/t/accounting-for-resources-in-waku-and-beyond/31">https://forum.vac.dev/t/accounting-for-resources-in-waku-and-beyond/31<!-- --></a> for discussion.<!-- --></p>
<!-- --><p>We also note that in GossipSub, the mesh is bidrectional. Additionally, it doesn&#x27;t appears to be a high priority issue in terms of nodes misreporting. What is an issue is having people run full nodes in the first place. There are a few points to that. It has to be possible in the end-user UX, nodes have to be discovered, and it has to be profitable/visible that you are contributing. UX and discovery are out of scope for this work, whereas visibility/accounting is part of this scope. Settlement is a stretch goal here.<!-- --></p>
<!-- --><p>The general shape of the solution is inspired by the Swarm model, where we do accounting separate from settlement. It doesn&#x27;t require any specific proofs, but nodes are incentivized to tell the truth in the following way:<!-- --></p>
<!-- --><ol>
<!-- --><li>Both full node and light node do accounting in a pairwise, local fashion<!-- --></li>
<!-- --><li>If a light node doesn&#x27;t ultimately pay or lie about reporting, they get disconnected (e.g.)<!-- --></li>
<!-- --><li>If a full node doesn&#x27;t provide its service the light node may pick another full node (e.g.)<!-- --></li>
<!-- --></ol>
<!-- --><p>While accounting for individual resource usage is useful, for the ultimate end user experience we can ideally account for other things such as:<!-- --></p>
<!-- --><ul>
<!-- --><li>end to end delivery<!-- --></li>
<!-- --><li>online time<!-- --></li>
<!-- --><li>completeness of storage<!-- --></li>
<!-- --></ul>
<!-- --><p>This can be gradually enhanced and strengthened, for example with proofs, consistency checks, Quality of Service, reputation systems. See <!-- --><a href="https://discuss.status.im/t/network-incentivisation-first-draft/1037">https://discuss.status.im/t/network-incentivisation-first-draft/1037<!-- --></a> for one attempt to provide stronger guarantees with periodic consistency checks and a shared fund mechanism. And <!-- --><a href="https://forum.vac.dev/t/incentivized-messaging-using-validity-proofs/51">https://forum.vac.dev/t/incentivized-messaging-using-validity-proofs/51<!-- --></a> for using validity proofs and removing liveness requirement for settlement.<!-- --></p>
<!-- --><p>All of this is optional at this stage, because our goal here is to improve the status quo for user run nodes. Accounting at this stage should be visible and correspond to the net benefit a node provides to another.<!-- --></p>
<!-- --><p>As a concrete example: a light node has some topic interest and cares about historical messages on some topic. A full node communicates envelopes as they come in, communicates their high availability (online time) and stores/forward stored messages. Both nodes have this information, and if they agree settlement (initially just a mock message) can be sending a payment to an address at some time interval / over some defined volume. See future sections for how this can be improved upon.<!-- --></p>
<!-- --><p>Also see below in section 4, using constructs such as eigentrust as a local reputation mechanism.<!-- --></p>
<!-- --><h3><a class="anchor" id="3-relax-high-availability-requirement"></a><a class="ha" href="#3-relax-high-availability-requirement">3. Relax high availability requirement<!-- --></a></h3>
<!-- --><p>If we want desktop nodes to participate in the storing of historical messages, high availability is a problem. It is a problem for any node, especially if they lie about it, but assuming they are honest it is still an issue.<!-- --></p>
<!-- --><p>By being connected to multiple nodes, we can get an overlapping online window. Then these can be combined together to get consistency. This is obviously experimental and would need to be tested before being deployed, but if it works it&#x27;d be very useful.<!-- --></p>
<!-- --><p>Additionally or alternatively, instead of putting a high requirement on message availability, focus on detection of missing information. This likely requires re-thinking how we do data sync / replication.<!-- --></p>
<!-- --><h3><a class="anchor" id="4-incentivize-light-and-full-nodes-to-tell-the-truth-policy-etc"></a><a class="ha" href="#4-incentivize-light-and-full-nodes-to-tell-the-truth-policy-etc">4. Incentivize light and full nodes to tell the truth (policy, etc)<!-- --></a></h3>
<!-- --><p>In accounting phase it is largely assumed nodes are honest. What happens when they lie, and how do we incentivize them to be honest? In the case of Bittorrent this is done with tit-for-tat, however this is a different kind of relationship. What follows are some examples of how this can be done.<!-- --></p>
<!-- --><p>For light nodes:<!-- --></p>
<!-- --><ul>
<!-- --><li>if they don&#x27;t, they get disconnected<!-- --></li>
<!-- --><li>prepayment (especially to &quot;high value&quot; nodes)<!-- --></li>
<!-- --></ul>
<!-- --><p>For full nodes:<!-- --></p>
<!-- --><ul>
<!-- --><li>multiple nodes reporting to agree, where truth becomes a shelling point<!-- --></li>
<!-- --><li>use eigentrust<!-- --></li>
<!-- --><li>staking for discovery visibility with slashing<!-- --></li>
<!-- --></ul>
<!-- --><h3><a class="anchor" id="5-settlement-poc"></a><a class="ha" href="#5-settlement-poc">5. Settlement PoC<!-- --></a></h3>
<!-- --><p>Can be done after phase 2 if so desired. Basically integrate payments based on accounting and policy.<!-- --></p>
<!-- --><h1><a class="anchor" id="out-of-scope"></a><a class="ha" href="#out-of-scope">Out of scope<!-- --></a></h1>
<!-- --><ol>
<!-- --><li>We assume the Status Base model requirements are accurate.<!-- --></li>
<!-- --><li>We assume Core will improve retention rates.<!-- --></li>
<!-- --><li>We assume the Stimbus production team will enable integration of nim-waku.<!-- --></li>
<!-- --><li>We assume Discovery mechanisms such as DNS and Discovery v5 will be worked on separately.<!-- --></li>
<!-- --><li>We assume Core will, at some point, provide an UX for integrating payment of services.<!-- --></li>
<!-- --><li>We assume the desktop client is sufficiently usable.<!-- --></li>
<!-- --><li>We assume Core and Infra will investigate ways of improving MaxPeers.<!-- --></li>
<!-- --></ol></article><aside class="Styles_container__3DqFl Style_toc__v7JJe Styles_common_toc__nMHyQ hidden-scroll"><nav class="Styles_tocComponent__fhPld hidden-scroll"><ul><li class="h-1"><a class="" href="/waku-v2-plan#problem">Problem</a></li><li class="h-1"><a class="" href="/waku-v2-plan#appetite">Appetite</a></li><li class="h-1"><a class="" href="/waku-v2-plan#solution">Solution</a></li><li class="h-2"><a class="" href="/waku-v2-plan#baseline">Baseline</a></li><li class="h-2"><a class="" href="/waku-v2-plan#track-1-move-to-libp2p">Track 1 - Move to libp2p</a></li><li class="h-3"><a class="" href="/waku-v2-plan#flood-sub">FloodSub</a></li><li class="h-3"><a class="" href="/waku-v2-plan#simplify-the-protocol">Simplify the protocol</a></li><li class="h-3"><a class="" href="/waku-v2-plan#core-integration">Core integration</a></li><li class="h-3"><a class="" href="/waku-v2-plan#topic-interest-behavior">Topic interest behavior</a></li><li class="h-3"><a class="" href="/waku-v2-plan#historical-message-caching">Historical message caching</a></li><li class="h-3"><a class="" href="/waku-v2-plan#waku-v1-libp2p-bridge">Waku v1  Libp2p bridge</a></li><li class="h-2"><a class="" href="/waku-v2-plan#track-2-better-routing">Track 2 - Better routing</a></li><li class="h-3"><a class="" href="/waku-v2-plan#gossip-sub">GossipSub</a></li><li class="h-3"><a class="" href="/waku-v2-plan#topic-sharding">Topic sharding</a></li><li class="h-3"><a class="" href="/waku-v2-plan#other-factors">Other factors</a></li><li class="h-2"><a class="" href="/waku-v2-plan#track-3-accounting-and-user-run-nodes">Track 3 - Accounting and user-run nodes</a></li><li class="h-3"><a class="" href="/waku-v2-plan#adaptive-nodes-and-capabilities">Adaptive nodes and capabilities</a></li><li class="h-3"><a class="" href="/waku-v2-plan#accounting">Accounting</a></li><li class="h-3"><a class="" href="/waku-v2-plan#relax-high-availability-requirement">Relax high availability requirement</a></li><li class="h-3"><a class="" href="/waku-v2-plan#incentivize-light-and-full-nodes-to-tell-the-truth-policy-etc">Incentivize light and full nodes to tell the truth (policy, etc)</a></li><li class="h-3"><a class="" href="/waku-v2-plan#settlement-po-c">Settlement PoC</a></li><li class="h-1"><a class="" href="/waku-v2-plan#out-of-scope">Out of scope</a></li></ul></nav></aside></main><footer class="Styles_container___YkOC undefined Styles_common_footer__1rPoh"><div class="footer-content-container Styles_content__0jn9p"><div><p><span class="copy-left">©</span><span>2023<!-- --></span><span> Vac Research</span><span> - </span><span>Vac - Communication, Privacy, Etc</span></p></div><div class="Styles_bottomPart__CsMh_"><div class="Styles_socialMedia__AmAKz "><span><a href="https://twitter.com/vacp2p" class="button"><svg xmlns="http://www.w3.org/2000/svg" width="30" viewBox="0 0 543.684 543.684" xml:space="preserve"><path d="M527.657 106.697a231.362 231.362 0 0 1-8.041 2.191c-16.384 4.137-17.89-1.322-6.028-13.366a109.306 109.306 0 0 0 14.082-17.607c9.137-14.217 1.212-20.417-14.333-13.776a224.853 224.853 0 0 1-16.897 6.432c-16.017 5.379-38.746-2.735-53.018-11.787-18.018-11.426-38.495-17.136-61.438-17.136-32.137 0-59.529 11.334-82.192 33.984-22.656 22.662-33.99 50.062-33.99 82.191 0 4.394.251 8.855.747 13.378.814 7.362-11.585 12.699-28.317 10.336-36.194-5.11-70.582-16.077-103.171-32.889-32.32-16.671-60.845-37.65-85.57-62.938-11.819-12.086-27.804-11.045-32.217 5.27-2.644 9.78-3.959 19.951-3.959 30.515 0 19.908 4.675 38.372 14.027 55.392 4.651 8.47 10.098 16.138 16.353 22.999 10.521 11.549 8.911 18.25-5.734 14.144-14.639-4.106-25.367-10.202-25.367-9.804v.722c0 28.048 8.807 52.693 26.432 73.911 10.857 13.072 23.47 23.17 37.834 30.282 15.147 7.503 22.203 11.688 13.733 12.784-5.11.661-10.251.991-15.422.991-3.5 0-7.172-.159-11.003-.483-6.059-.514-7.148 12.111 2.038 26.298 7.301 11.273 16.646 21.193 28.03 29.762 11.579 8.721 24.058 14.981 37.417 18.794 16.255 4.633 19.517 13.073 5.024 21.763-35.863 21.519-75.551 32.277-119.058 32.277-4.902 0-9.578-.11-14.045-.324-7.754-.373-2.552 6.456 12.417 14.296 46.775 24.499 97.43 36.738 151.972 36.738 41.237 0 79.964-6.529 116.176-19.596 36.199-13.066 67.136-30.576 92.791-52.516 25.655-21.94 47.779-47.173 66.365-75.711 18.581-28.537 32.424-58.33 41.543-89.376 9.106-31.053 13.666-62.167 13.666-93.342 0-2.809-.024-5.331-.067-7.552-.086-4.174 10.955-15.472 23.28-27.032a242.397 242.397 0 0 0 15.937-16.444c11.179-12.688 6.228-18.502-9.997-13.771z"></path></svg></a></span><span><a href="https://discord.gg/PQFdubGt6d" class="button"><svg width="30" viewBox="0 0 71 55" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#discord_svg__a)"><path d="M60.105 4.898A58.55 58.55 0 0 0 45.653.415a.22.22 0 0 0-.233.11 40.784 40.784 0 0 0-1.8 3.697c-5.456-.817-10.886-.817-16.23 0-.485-1.164-1.201-2.587-1.828-3.697a.228.228 0 0 0-.233-.11 58.386 58.386 0 0 0-14.451 4.483.207.207 0 0 0-.095.082C1.578 18.73-.944 32.144.293 45.39a.244.244 0 0 0 .093.167c6.073 4.46 11.955 7.167 17.729 8.962a.23.23 0 0 0 .249-.082 42.08 42.08 0 0 0 3.627-5.9.225.225 0 0 0-.123-.312 38.772 38.772 0 0 1-5.539-2.64.228.228 0 0 1-.022-.378c.372-.279.744-.569 1.1-.862a.22.22 0 0 1 .23-.03c11.619 5.304 24.198 5.304 35.68 0a.219.219 0 0 1 .233.027c.356.293.728.586 1.103.865a.228.228 0 0 1-.02.378 36.384 36.384 0 0 1-5.54 2.637.227.227 0 0 0-.121.315 47.249 47.249 0 0 0 3.624 5.897.225.225 0 0 0 .249.084c5.801-1.794 11.684-4.502 17.757-8.961a.228.228 0 0 0 .092-.164c1.48-15.315-2.48-28.618-10.497-40.412a.18.18 0 0 0-.093-.084Zm-36.38 32.427c-3.497 0-6.38-3.211-6.38-7.156 0-3.944 2.827-7.156 6.38-7.156 3.583 0 6.438 3.24 6.382 7.156 0 3.945-2.827 7.156-6.381 7.156Zm23.593 0c-3.498 0-6.38-3.211-6.38-7.156 0-3.944 2.826-7.156 6.38-7.156 3.582 0 6.437 3.24 6.38 7.156 0 3.945-2.798 7.156-6.38 7.156Z" fill="#23272A"></path></g><defs><clipPath id="discord_svg__a"><path fill="#fff" d="M0 0h71v55H0z"></path></clipPath></defs></svg></a></span><span><a href="https://github.com/vacp2p" class="button"><svg width="30" viewBox="0 0 1024 1024" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M512 0C229.12 0 0 229.12 0 512c0 226.56 146.56 417.92 350.08 485.76 25.6 4.48 35.2-10.88 35.2-24.32 0-12.16-.64-52.48-.64-95.36-128.64 23.68-161.92-31.36-172.16-60.16-5.76-14.72-30.72-60.16-52.48-72.32-17.92-9.6-43.52-33.28-.64-33.92 40.32-.64 69.12 37.12 78.72 52.48 46.08 77.44 119.68 55.68 149.12 42.24 4.48-33.28 17.92-55.68 32.64-68.48-113.92-12.8-232.96-56.96-232.96-252.8 0-55.68 19.84-101.76 52.48-137.6-5.12-12.8-23.04-65.28 5.12-135.68 0 0 42.88-13.44 140.8 52.48 40.96-11.52 84.48-17.28 128-17.28 43.52 0 87.04 5.76 128 17.28 97.92-66.56 140.8-52.48 140.8-52.48 28.16 70.4 10.24 122.88 5.12 135.68 32.64 35.84 52.48 81.28 52.48 137.6 0 196.48-119.68 240-233.6 252.8 18.56 16 34.56 46.72 34.56 94.72 0 68.48-.64 123.52-.64 140.8 0 13.44 9.6 29.44 35.2 24.32C877.44 929.92 1024 737.92 1024 512 1024 229.12 794.88 0 512 0Z" fill="#1B1F23"></path></svg></a></span></div><nav class="Styles_legal__0ciDG"><a title="Privacy Policy" href="/privacy-policy">Privacy Policy</a></nav></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"markdown":{"content":"\n**tldr: The Waku network is fragile and doesn't scale. Here's how to solve it.**\n\n*NOTE: This post was originally written with Status as a primary use case in mind, which reflects how we talk about some problems here. However, Waku v2 is a general-purpose private p2p messaging protocol, especially for people running in resource restricted environments.*\n\n# Problem\n\nThe Waku network is fragile and doesn't scale.\n\nAs [Status](https://status.im) is moving into a user-acquisition phase and is improving retention rates for users they need the infrastructure to keep up, specifically when it comes to messaging.\n\nBased on user acquisition models, the initial goal is to support 100k DAU in September, with demand growing from there.\n\nWith the Status Scaling Model we have studied the current bottlenecks as a function of concurrent users (CCU) and daily active users (DAU). Here are the conclusions.\n\n****1. Connection limits****. With 100 full nodes we reach ~10k CCU based on connection limits. This can primarily be addressed by increasing the number of nodes (cluster or user operated). This assumes node discovery works. It is also worth investigating the limitations of max number of connections, though this is likely to be less relevant for user-operated nodes. For a user-operated network, this means 1% of users have to run a full node. See Fig 1-2.\n\n****2. Bandwidth as a bottleneck****. We notice that memory usage appears to not be\nthe primary bottleneck for full nodes, and the bottleneck is still bandwidth. To support 10k DAU, and full nodes with an amplification factor of 25 the required Internet speed is ~50 Mbps, which is a fast home Internet connection. For ~100k DAU only cloud-operated nodes can keep up (500 Mbps). See Fig 3-5.\n\n****3. Amplification factors****. Reducing amplification factors with better routing, would have a high impact, but it is likely we'd need additional measures as well, such as topic sharding or similar. See Fig 8-13.\n\nFigure 1-5:\n\n![](/img/status_scaling_model_fig1.png)\n![](/img/status_scaling_model_fig2.png)\n![](/img/status_scaling_model_fig3.png)\n![](/img/status_scaling_model_fig4.png)\n![](/img/status_scaling_model_fig5.png)\n\nSee \u003chttps://colab.research.google.com/drive/1Fz-oxRxxAFPpM1Cowpnb0nT52V1-yeRu#scrollTo=Yc3417FUJJ_0\u003e for the full report.\n\nWhat we need to do is:\n\n1.  Reduce amplification factors\n2.  Get more user-run full nodes\n\nDoing this means the Waku network will be able to scale, and doing so in the right way, in a robust fashion. What would a fragile way of scaling be? Increasing our reliance on a Status Pte Ltd operated cluster which would paint us in a corner where we:\n\n-   keep increasing requirements for Internet speed for full nodes\n-   are vulnerable to censorship and attacks\n-   have to control the topology in an artifical manner to keep up with load\n-   basically re-invent a traditional centralized client-server app with extra steps\n-   deliberately ignore most of our principles\n-   risk the network being shut down when we run out of cash\n\n# Appetite\n\nOur initial risk appetite for this is 6 weeks for a small team.\n\nThe idea is that we want to make tangible progress towards the goal in a limited period of time, as opposed to getting bogged down in trying to find a theoretically perfect generalized solution. Fixed time, variable scope.\n\nIt is likely some elements of a complete solution will be done separately. See later sections for that.\n\n# Solution\n\nThere are two main parts of the solution. One is to reduce amplification factors, and the other is incentivization to get more user run full nodes with desktop, etc.\n\nWhat does a full node provide? It provides connectivity to the network, can act as a bandwidth \"barrier\" and be high or reasonably high availability. What this means right now is essentially topic interest and storing historical messages.\n\nThe goal is here to improve the status quo, not get a perfect solution from the get go. All of this can be iterated on further, for stronger guarantees, as well as replaced by other new modules.\n\nLet's first look at the baseline, and then go into some of the tracks and their phases. Track 1 is best done first, after which track 2 and 3 can be executed in parallel. Track 1 gives us more options for track 2 and 3. The work in track 1 is currently more well-defined, so it is likely the specifics of track 2 and 3 will get refined at a later stage.\n\n## Baseline\n\nHere's where we are at now. In reality, the amplification factor are likely even worse than this (15 in the graph below), up to 20-30. Especially with an open network, where we can't easily control connectivity and availability of nodes. Left unchecked, with a full mesh, it could even go as high x100, though this is likely excessive and can be dialed down. See scaling model for more details.\n\n\n![](/img/waku_v1_routing_small.png)\n\n## Track 1 - Move to libp2p\n\nMoving to PubSub over libp2p wouldn't improve amplification per se, but it would be stepping stone. Why? It paves the way for GossipSub, and would be a checkpoint on this journey. Additionally, FloodSub and GossipSub are compatible, and very likely other future forms of PubSub such as GossipSub 1.1 (hardened/more secure), EpiSub, forwarding Kademlia / PubSub over Kademlia, etc. Not to mention security This would also give us access to the larger libp2p ecosystem (multiple protocols, better encryption, quic, running in the browser, security audits, etc, etc), as well as be a joint piece of infrastructured used for Eth2 in Nimbus. More wood behind fewer arrows.\n\nSee more on libp2p PubSub here: \u003chttps://docs.libp2p.io/concepts/publish-subscribe/\u003e\n\nAs part of this move, there are a few individual pieces that are needed.\n\n### 1. FloodSub\n\nThis is essentially what Waku over libp2p would look like in its most basic form.\n\nOne difference that is worth noting is that the app topics would **not** be the same as Waku topics. Why? In Waku we currently don't use topics for routing between full nodes, but only for edge/light nodes in the form of topic interest. In FloodSub, these topics are used for routing.\n\nWhy can't we use Waku topics for routing directly? PubSub over libp2p isn't built for rare and ephemeral topics, and nodes have to explicitly subscribe to a topic. See topic sharding section for more on this.\n\n![](/img/waku_v2_routing_flood_small.png)\n\n\nMoving to FloodSub over libp2p would also be an opportunity to clean up and simplify some components that are no longer needed in the Waku v1 protocol, see point below.\n\nVery experimental and incomplete libp2p support can be found in the nim-waku repo under v2: \u003chttps://github.com/status-im/nim-waku\u003e\n\n### 2. Simplify the protocol\n\nDue to Waku's origins in Whisper, devp2p and as a standalone protocol, there are a lot of stuff that has accumulated (\u003chttps://rfc.vac.dev/spec/6/\u003e). Not all of it serves it purpose anymore. For example, do we still need RLP here when we have Protobuf messages? What about extremely low PoW when we have peer scoring? What about key management / encryption when have encryption at libp2p and Status protocol level?\n\nNot everything has to be done in one go, but being minimalist at this stage will the protocol lean and make us more adaptable.\n\nThe essential characteristic that has to be maintained is that we don't need to change the upper layers, i.e. we still deal with (Waku) topics and some envelope like data unit.\n\n### 3. Core integration\n\nAs early as possible we want to integrate with Core via Stimbus in order to mitigate risk and catch integration issues early in the process. What this looks like in practice is some set of APIs, similar to how Whisper and Waku were working in parallel, and experimental feature behind a toggle in core/desktop.\n\n### 4. Topic interest behavior\n\nWhile we target full node traffic here, we want to make sure we maintain the existing bandwidth requirements for light nodes that Waku v1 addressed (\u003chttps://vac.dev/fixing-whisper-with-waku\u003e). This means implementing topic-interest in the form of Waku topics. Note that this would be separate from app topics notes above.\n\n### 5. Historical message caching\n\nBasically what mailservers are currently doing. This likely looks slightly different in a libp2p world. This is another opportunity to simplify things with a basic REQ-RESP architecture, as opposed to the roundabout way things are now. Again, not everything has to be done in one go but there's no reason to reimplement a poor API if we don't have to.\n\nAlso see section below on adaptive nodes and capabilities.\n\n### 6. Waku v1 \u003c\u003e Libp2p bridge\n\nTo make the transition complete, there has to a be bridge mode between current Waku and libp2p. This is similar to what was done for Whisper and Waku, and allows any nodes in the network to upgrade to Waku v2 at their leisure. For example, this would likely look different for Core, Desktop, Research and developers.\n\n## Track 2 - Better routing\n\nThis is where we improve the amplification factors.\n\n### 1. GossipSub\n\nThis is a subprotocol of FloodSub in the libp2p world. Moving to GossipSub would allow traffic between full nodes to go from an amplification factor of ~25 to ~6. This basically creates a mesh of stable bidirectional connections, together with some gossiping capabilities outside of this view.\n\nExplaining how GossipSub works is out of scope of this document. It is implemented in nim-libp2p and used by Nimbus as part of Eth2. You can read the specs here in more detail if you are interested: \u003chttps://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.0.md\u003e and \u003chttps://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md\u003e\n\n![](/img/waku_v2_routing_gossip_small.png)\n\n![](/img/status_scaling_model_fig8.png)\n![](/img/status_scaling_model_fig9.png)\n![](/img/status_scaling_model_fig10.png)\n![](/img/status_scaling_model_fig11.png)\n\nWhile we technically could implement this over existing Waku, we'd have to re-implement it, and we'd lose out on all the other benefits libp2p would provide, as well as the ecosystem of people and projects working on improving the scalability and security of these protocols.\n\n### 2. Topic sharding\n\nThis one is slightly more speculative in terms of its ultimate impact. The basic idea is to split the application topic into N shards, say 10, and then each full node can choose which shards to listen to. This can reduce amplification factors by another factor of 10.\n\n![](/img/waku_v2_routing_sharding_small.png)\n\n![](/img/status_scaling_model_fig12.png)\n![](/img/status_scaling_model_fig13.png)\n\nNote that this means a light node that listens to several topics would have to be connected to more full nodes to get connectivity. For a more exotic version of this, see \u003chttps://forum.vac.dev/t/rfc-topic-propagation-extension-to-libp2p-pubsub/47\u003e\n\nThis is orthogonal from the choice of FloodSub or GossipSub, but due to GossipSub's more dynamic nature it is likely best combined with it.\n\n### 3. Other factors\n\nNot a primary focus, but worth a look. Looking at the scaling model, there might be other easy wins to improve overall bandwidth consumption between full nodes. For example, can we reduce envelope size by a significant factor?\n\n## Track 3 - Accounting and user-run nodes\n\nThis is where we make sure the network isn't fragile, become a true p2p app, get our users excited and engaged, and allow us to scale the network without creating an even bigger cluster.\n\nTo work in practice, this has a soft dependency on node discovery such as DNS based discovery (\u003chttps://eips.ethereum.org/EIPS/eip-1459\u003e) or Discovery v5 (\u003chttps://vac.dev/feasibility-discv5\u003e).\n\n### 1. Adaptive nodes and capabilities\n\nWe want to make the gradation between light nodes, full nodes, storing (partial set of) historical messages, only acting for a specific shard, etc more flexible and explicit. This is required to identify and discover the nodes you want. See \u003chttps://github.com/vacp2p/specs/issues/87\u003e\n\nDepending on how the other tracks come together, this design should allow for a desktop node to identify as a full relaying node for some some app topic shard, but also express waku topic interest and retrieve historical messages itself.\n\nE.g. Disc v5 can be used to supply node properties through ENR.\n\n### 2. Accounting\n\nThis is based on a few principles:\n\n1.  Some nodes contribute a lot more than other nodes in the network\n2.  We can account for the difference in contribution in some fashion\n3.  We want to incentivize nodes to tell the true, and be incentivized not to lie\n\nAccounting here is a stepping stone, where accounting is the raw data upon which some settlement later occurs. It can have various forms of granularity. See \u003chttps://forum.vac.dev/t/accounting-for-resources-in-waku-and-beyond/31\u003e for discussion.\n\nWe also note that in GossipSub, the mesh is bidrectional. Additionally, it doesn't appears to be a high priority issue in terms of nodes misreporting. What is an issue is having people run full nodes in the first place. There are a few points to that. It has to be possible in the end-user UX, nodes have to be discovered, and it has to be profitable/visible that you are contributing. UX and discovery are out of scope for this work, whereas visibility/accounting is part of this scope. Settlement is a stretch goal here.\n\nThe general shape of the solution is inspired by the Swarm model, where we do accounting separate from settlement. It doesn't require any specific proofs, but nodes are incentivized to tell the truth in the following way:\n\n1.  Both full node and light node do accounting in a pairwise, local fashion\n2.  If a light node doesn't ultimately pay or lie about reporting, they get disconnected (e.g.)\n3.  If a full node doesn't provide its service the light node may pick another full node (e.g.)\n\nWhile accounting for individual resource usage is useful, for the ultimate end user experience we can ideally account for other things such as:\n\n-   end to end delivery\n-   online time\n-   completeness of storage\n\nThis can be gradually enhanced and strengthened, for example with proofs, consistency checks, Quality of Service, reputation systems. See \u003chttps://discuss.status.im/t/network-incentivisation-first-draft/1037\u003e for one attempt to provide stronger guarantees with periodic consistency checks and a shared fund mechanism. And \u003chttps://forum.vac.dev/t/incentivized-messaging-using-validity-proofs/51\u003e for using validity proofs and removing liveness requirement for settlement.\n\nAll of this is optional at this stage, because our goal here is to improve the status quo for user run nodes. Accounting at this stage should be visible and correspond to the net benefit a node provides to another.\n\nAs a concrete example: a light node has some topic interest and cares about historical messages on some topic. A full node communicates envelopes as they come in, communicates their high availability (online time) and stores/forward stored messages. Both nodes have this information, and if they agree settlement (initially just a mock message) can be sending a payment to an address at some time interval / over some defined volume. See future sections for how this can be improved upon.\n\nAlso see below in section 4, using constructs such as eigentrust as a local reputation mechanism.\n\n### 3. Relax high availability requirement\n\nIf we want desktop nodes to participate in the storing of historical messages, high availability is a problem. It is a problem for any node, especially if they lie about it, but assuming they are honest it is still an issue.\n\nBy being connected to multiple nodes, we can get an overlapping online window. Then these can be combined together to get consistency. This is obviously experimental and would need to be tested before being deployed, but if it works it'd be very useful.\n\nAdditionally or alternatively, instead of putting a high requirement on message availability, focus on detection of missing information. This likely requires re-thinking how we do data sync / replication.\n\n### 4. Incentivize light and full nodes to tell the truth (policy, etc)\n\nIn accounting phase it is largely assumed nodes are honest. What happens when they lie, and how do we incentivize them to be honest? In the case of Bittorrent this is done with tit-for-tat, however this is a different kind of relationship. What follows are some examples of how this can be done.\n\nFor light nodes:\n\n-   if they don't, they get disconnected\n-   prepayment (especially to \"high value\" nodes)\n\nFor full nodes:\n\n-   multiple nodes reporting to agree, where truth becomes a shelling point\n-   use eigentrust\n-   staking for discovery visibility with slashing\n\n### 5. Settlement PoC\n\nCan be done after phase 2 if so desired. Basically integrate payments based on accounting and policy.\n\n# Out of scope\n\n1.  We assume the Status Base model requirements are accurate.\n2.  We assume Core will improve retention rates.\n3.  We assume the Stimbus production team will enable integration of nim-waku.\n4.  We assume Discovery mechanisms such as DNS and Discovery v5 will be worked on separately.\n5.  We assume Core will, at some point, provide an UX for integrating payment of services.\n6.  We assume the desktop client is sufficiently usable.\n7.  We assume Core and Infra will investigate ways of improving MaxPeers.\n","metadata":{"layout":"post","name":"What's the Plan for Waku v2?","title":"What's the Plan for Waku v2?","date":"2020-07-01T12:00:00.000Z","author":"oskarth","published":true,"permalink":"/waku-v2-plan","categories":"research","summary":"Read about our plans for Waku v2, moving to libp2p, better routing, adaptive nodes and accounting!","image":"/img/status_scaling_model_fig4.png","discuss":"https://forum.vac.dev/t/waku-version-2-pitch/52"},"toc":[{"content":"Problem","slug":"problem","lvl":1,"i":0,"seen":0},{"content":"Appetite","slug":"appetite","lvl":1,"i":1,"seen":0},{"content":"Solution","slug":"solution","lvl":1,"i":2,"seen":0},{"content":"Baseline","slug":"baseline","lvl":2,"i":3,"seen":0},{"content":"Track 1 - Move to libp2p","slug":"track-1-move-to-libp2p","lvl":2,"i":4,"seen":0},{"content":"FloodSub","slug":"flood-sub","lvl":3,"i":5,"seen":0},{"content":"Simplify the protocol","slug":"simplify-the-protocol","lvl":3,"i":6,"seen":0},{"content":"Core integration","slug":"core-integration","lvl":3,"i":7,"seen":0},{"content":"Topic interest behavior","slug":"topic-interest-behavior","lvl":3,"i":8,"seen":0},{"content":"Historical message caching","slug":"historical-message-caching","lvl":3,"i":9,"seen":0},{"content":"Waku v1  Libp2p bridge","slug":"waku-v1-libp2p-bridge","lvl":3,"i":10,"seen":0},{"content":"Track 2 - Better routing","slug":"track-2-better-routing","lvl":2,"i":11,"seen":0},{"content":"GossipSub","slug":"gossip-sub","lvl":3,"i":12,"seen":0},{"content":"Topic sharding","slug":"topic-sharding","lvl":3,"i":13,"seen":0},{"content":"Other factors","slug":"other-factors","lvl":3,"i":14,"seen":0},{"content":"Track 3 - Accounting and user-run nodes","slug":"track-3-accounting-and-user-run-nodes","lvl":2,"i":15,"seen":0},{"content":"Adaptive nodes and capabilities","slug":"adaptive-nodes-and-capabilities","lvl":3,"i":16,"seen":0},{"content":"Accounting","slug":"accounting","lvl":3,"i":17,"seen":0},{"content":"Relax high availability requirement","slug":"relax-high-availability-requirement","lvl":3,"i":18,"seen":0},{"content":"Incentivize light and full nodes to tell the truth (policy, etc)","slug":"incentivize-light-and-full-nodes-to-tell-the-truth-policy-etc","lvl":3,"i":19,"seen":0},{"content":"Settlement PoC","slug":"settlement-po-c","lvl":3,"i":20,"seen":0},{"content":"Out of scope","slug":"out-of-scope","lvl":1,"i":21,"seen":0}]},"navProps":{"metadata":{"published":true,"title":"What's the Plan for Waku v2?","layout":"post","name":"What's the Plan for Waku v2?","date":"2020-07-01T12:00:00.000Z","author":"oskarth","permalink":"/waku-v2-plan","categories":"research","summary":"Read about our plans for Waku v2, moving to libp2p, better routing, adaptive nodes and accounting!","image":"img/status_scaling_model_fig4.png","discuss":"https://forum.vac.dev/t/waku-version-2-pitch/52"},"navOrder":1593604800,"localPath":"research/2020-07-01-waku-v2-pitch.md","path":["waku-v2-plan"],"children":[],"isDir":false},"routeParams":{"path":["waku-v2-plan"]}},"__N_SSG":true},"page":"/[[...path]]","query":{"path":["waku-v2-plan"]},"buildId":"eRPxRFLrljDMNz1vMxWIY","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>